<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deepanway Ghoshal | Somak Aditya</title>
    <link>https://adityasomak.github.io/authors/deepanway-ghoshal/</link>
      <atom:link href="https://adityasomak.github.io/authors/deepanway-ghoshal/index.xml" rel="self" type="application/rss+xml" />
    <description>Deepanway Ghoshal</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 17 Jan 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://adityasomak.github.io/img/icon-192.png</url>
      <title>Deepanway Ghoshal</title>
      <link>https://adityasomak.github.io/authors/deepanway-ghoshal/</link>
    </image>
    
    <item>
      <title>STUCK IN THE QUICKSAND OF NUMERACY, FAR FROM AGI SUMMIT: EVALUATING LLMS&#39; MATHEMATICAL COMPETENCY THROUGH ONTOLOGY-GUIDED PERTURBATIONS</title>
      <link>https://adityasomak.github.io/publication/more24/</link>
      <pubDate>Wed, 17 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/more24/</guid>
      <description>&lt;p&gt;Recent advancements in Large Language Models (LLMs) have showcased striking results on existing logical reasoning benchmarks, with some models even surpassing human performance. However, the true depth of their competencies and robustness, in mathematical reasoning tasks, remains an open question. In response, we develop (i) an ontology of perturbations of maths questions, (ii) a semi-automatic method of perturbation, and (iii) a dataset of perturbed maths questions
to probe the limits of LLM capabilities in mathematical-reasoning tasks.
These controlled perturbations span across multiple fine dimensions of the structural and representational aspects of maths questions. Using GPT-4, we generated the &lt;span style=&#34;font-variant-caps: small-caps&#34;&gt;More&lt;/span&gt; dataset by perturbing randomly selected five seed questions from GSM8K. This process was guided by our ontology and involved a thorough automatic and manual filtering process, yielding a set of 216 maths problems.
We conducted comprehensive evaluation of both closed-source and open-source LLMs on &lt;span style=&#34;font-variant-caps: small-caps&#34;&gt;More&lt;/span&gt;. The results show a significant performance drop across all the models against the perturbed questions. This strongly suggests that current LLMs lack robust mathematical skills and a deep understanding of reasoning. This research not only identifies multiple gaps in the capabilities of current models, but also highlights multiple potential directions for future development. Our dataset will be made publicly available at &lt;a href=&#34;https://huggingface.co/datasets/declare-lab/GSM8k_MORE&#34;&gt;huggingface library&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prover: Generating Intermediate Steps for NLI with Commonsense Knowledge Retrieval and Next-Step Prediction</title>
      <link>https://adityasomak.github.io/publication/multihop/</link>
      <pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/multihop/</guid>
      <description>&lt;p&gt;The Natural Language Inference (NLI) task often requires reasoning over multiple steps to reach the conclusion. While the necessity of generating such intermediate steps (instead of a summary explanation) has gained popular support, it is unclear how to generate such steps without complete end-to-end supervision and how such generated steps can be further utilized. In this work, we train and enhance a sequence-to-sequence next-step prediction model with external commonsense knowledge and search to generate intermediate steps with limited next-step supervision. We show the correctness of such generated steps through human verification, on MNLI and MED datasets (and discuss the limitations through qualitative examples). We show that such generated steps can help improve end-to-end NLI task performance using simple data augmentation strategies. Using a CheckList dataset for NLI, we also explore the effect of augmentation on specific reasoning types.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vector Space Interpolation for Query Expansion</title>
      <link>https://adityasomak.github.io/publication/interpolation/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/interpolation/</guid>
      <description>&lt;p&gt;Topic-sensitive query set expansion is an important area of research that aims to improve search results for information retrieval. It is particularly crucial for queries related to sensitive and emerging topics. In this work, we describe a method for query set expansion about emerging topics using vector space interpolation. We use a transformer model called OPTIMUS, which is suitable for vector space manipulation due to its variational autoencoder nature. One of our proposed methods â€“ Dirichlet interpolation shows promising results for query expansion. Our methods effectively generate new queries about the sensitive topic by incorporating set-level diversity, which is not captured by traditional sentence-level augmentation methods such as paraphrasing or back-translation.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
