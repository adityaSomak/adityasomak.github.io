<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 | Somak Aditya</title>
    <link>https://adityasomak.github.io/publication_types/1/</link>
      <atom:link href="https://adityasomak.github.io/publication_types/1/index.xml" rel="self" type="application/rss+xml" />
    <description>1</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 16 May 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://adityasomak.github.io/img/icon-192.png</url>
      <title>1</title>
      <link>https://adityasomak.github.io/publication_types/1/</link>
    </image>
    
    <item>
      <title>STUCK IN THE QUICKSAND OF NUMERACY, FAR FROM AGI SUMMIT: EVALUATING LLMS&#39; MATHEMATICAL COMPETENCY THROUGH ONTOLOGY-GUIDED PERTURBATIONS</title>
      <link>https://adityasomak.github.io/publication/more24/</link>
      <pubDate>Fri, 16 May 2025 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/more24/</guid>
      <description>&lt;p&gt;Recent advancements in Large Language Models (LLMs) have showcased striking results on existing logical reasoning benchmarks, with some models even surpassing human performance. However, the true depth of their competencies and robustness, in mathematical reasoning tasks, remains an open question. In response, we develop (i) an ontology of perturbations of maths questions, (ii) a semi-automatic method of perturbation, and (iii) a dataset of perturbed maths questions
to probe the limits of LLM capabilities in mathematical-reasoning tasks.
These controlled perturbations span across multiple fine dimensions of the structural and representational aspects of maths questions. Using GPT-4, we generated the &lt;span style=&#34;font-variant-caps: small-caps&#34;&gt;More&lt;/span&gt; dataset by perturbing randomly selected five seed questions from GSM8K. This process was guided by our ontology and involved a thorough automatic and manual filtering process, yielding a set of 216 maths problems.
We conducted comprehensive evaluation of both closed-source and open-source LLMs on &lt;span style=&#34;font-variant-caps: small-caps&#34;&gt;More&lt;/span&gt;. The results show a significant performance drop across all the models against the perturbed questions. This strongly suggests that current LLMs lack robust mathematical skills and a deep understanding of reasoning. This research not only identifies multiple gaps in the capabilities of current models, but also highlights multiple potential directions for future development. Our dataset will be made publicly available at &lt;a href=&#34;https://huggingface.co/datasets/declare-lab/GSM8k_MORE&#34;&gt;huggingface library&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SMAB: MAB based word Sensitivity Estimation Framework and its Applications in Adversarial Text Generation</title>
      <link>https://adityasomak.github.io/publication/smab/</link>
      <pubDate>Mon, 20 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/smab/</guid>
      <description>&lt;p&gt;To understand the complexity of sequence classification tasks, Hahn et al. (2021) proposed sensitivity as the number of disjoint subsets of the input sequence that can each be individually changed to change the output. Though effective, calculating sensitivity at scale using this framework is costly because of exponential time complexity. Therefore, we introduce a Sensitivity-based Multi-Armed Bandit framework (SMAB), which provides a scalable approach for calculating word-level local (sentence-level) and global (aggregated) sensitivities concerning an underlying text classifier for any dataset. We establish the effectiveness of our approach through various applications. We perform a case study on CHECKLIST generated sentiment analysis dataset where we show that our algorithm indeed captures intuitively high and low-sensitive words. Through experiments on multiple tasks and languages, we show that sensitivity can serve as a proxy for accuracy in the absence of gold data. Lastly, we show that guiding perturbation prompts using sensitivity values in adversarial example generation improves attack success rate by 15.58%, whereas using sensitivity as an additional reward in adversarial paraphrase generation gives a 12.00% improvement over SOTA approaches. Warning: Contains potentially offensive content.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning</title>
      <link>https://adityasomak.github.io/publication/mathsensei/</link>
      <pubDate>Thu, 14 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/mathsensei/</guid>
      <description>&lt;p&gt;Tool-augmented Large Language Models (TALM) are known to enhance the skillset of
large language models (LLM), thereby, leading to their improved reasoning abilities across
many tasks. While, TALMs have been successfully employed in different question-answering
benchmarks, their efficacy on complex mathematical reasoning benchmarks, and, the potential complimentary benefits offered by tools for knowledge retrieval and mathematical equation solving, are open research questions. In this work, we present MATHSENSEI, a toolaugmented large language model for mathematical reasoning. Augmented with tools for knowledge retrieval (Bing Web Search), program execution (Python), and symbolic equation solving (Wolfram-Alpha), we study the
complimentary benefits of these tools through evaluations on mathematical reasoning datasets.
We perform exhaustive ablations on MATH, a popular dataset for evaluating mathematical reasoning on diverse mathematical disciplines. We also conduct experiments involving well-known tool planners to study the impact of tool sequencing on the model performance. MATHSENSEI achieves 13.5% better accuracy over gpt-3.5-turbo with chain-ofthought on the MATH dataset. We further observe that TALMs are not as effective for simpler math word problems (in GSM-8k), and
the benefit increases as the complexity and required knowledge increases (progressively
over AQuA, MMLU-Math, and higher level complex questions in MATH). The code and data are available at &lt;a href=&#34;https://github.com/Debrup61/MathSensei&#34;&gt;MathSensei-Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks</title>
      <link>https://adityasomak.github.io/publication/promptinj/</link>
      <pubDate>Tue, 20 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/promptinj/</guid>
      <description>&lt;p&gt;Recent explorations with commercial Large Language Models (LLMs) have shown that non-expert users can jailbreak LLMs by simply manipulating the prompts; resulting in degenerate output behavior, privacy and security breaches, offensive outputs, and violations of content regulator policies. Limited formal studies have been carried out to formalize and analyze these attacks and their mitigations. We bridge this gap by proposing a formalism and a taxonomy of known (and possible) jailbreaks. We perform a survey of existing jailbreak methods and their effectiveness on open-source and commercial LLMs (such as GPT 3.5, OPT, BLOOM, and FLAN-T5-xxl). We further propose a limited set of prompt guards and discuss their effectiveness against known attack types.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prover: Generating Intermediate Steps for NLI with Commonsense Knowledge Retrieval and Next-Step Prediction</title>
      <link>https://adityasomak.github.io/publication/multihop/</link>
      <pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/multihop/</guid>
      <description>&lt;p&gt;The Natural Language Inference (NLI) task often requires reasoning over multiple steps to reach the conclusion. While the necessity of generating such intermediate steps (instead of a summary explanation) has gained popular support, it is unclear how to generate such steps without complete end-to-end supervision and how such generated steps can be further utilized. In this work, we train and enhance a sequence-to-sequence next-step prediction model with external commonsense knowledge and search to generate intermediate steps with limited next-step supervision. We show the correctness of such generated steps through human verification, on MNLI and MED datasets (and discuss the limitations through qualitative examples). We show that such generated steps can help improve end-to-end NLI task performance using simple data augmentation strategies. Using a CheckList dataset for NLI, we also explore the effect of augmentation on specific reasoning types.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SYNC: A Structurally guided Hard Negative Curricula for Efficient Neural Code Search</title>
      <link>https://adityasomak.github.io/publication/sync/</link>
      <pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/sync/</guid>
      <description>&lt;p&gt;In neural code search, a Transformers-based pre-trained language model (such as CodeBERT) is used to embed both the query (NL) and the code snippet (PL) into a joint representation space; which is used to retrieve the relevant PLs satisfying the query. These models often make mistakes such as retrieving snippets with incorrect data types, and incorrect method names or signatures. The generalization ability beyond training data is also limited (as the code retrieval datasets vary in the ways NL-PL pairs are collected). In this work, we propose a novel contrastive learning technique (SYNC) that enables efficient finetuning of code LMs with soft and hard negatives, where the hard negatives are constructed using a set of structure-aware AST-based perturbations; targeted towards possible syntactic and semantic variations.
Our method achieves significant improvements in retrieval performance for three code LMs (CodeBERT, GraphCodeBERT, UniXCoder) over four Python code retrieval datasets.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Robust Information-Masking Approach for Domain Counterfactual Generation</title>
      <link>https://adityasomak.github.io/publication/counterfactualda/</link>
      <pubDate>Wed, 03 May 2023 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/counterfactualda/</guid>
      <description>&lt;p&gt;Domain shift is a big challenge in NLP, thus, many approaches resort to learning domain-invariant features to mitigate the inference phase domain shift. Such methods, however, fail to leverage the domain-specific nuances relevant to the task at hand. To avoid such drawbacks, domain counterfactual generation aims to transform a text from the source domain to a given target domain. However, due to the limited availability of data, such frequency-based methods often miss and lead to some valid and spurious domain-token associations. Hence, we employ a three-step domain obfuscation approach that involves frequency and attention norm-based masking, to mask domain-specific cues, and unmasking to regain the domain generic context. Our experiments empirically show that the counterfactual samples sourced from our masked text lead to improved domain transfer on 10 out of 12 domain sentiment classification settings, with an average of 2% accuracy improvement over the state-of-the-art for unsupervised domain adaptation (UDA). Further our model outperforms the state-of-the-art by achieving 1.4% average accuracy improvement in the adversarial domain adaptation (ADA) setting. Moreover, our model also shows its domain adaptation efficacy on a large multi-domain intent classification dataset where it attains state-of-the-art results.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multilingual CheckList: Generation and Evaluation</title>
      <link>https://adityasomak.github.io/publication/amcg/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/amcg/</guid>
      <description>&lt;p&gt;The recently proposed CheckList (Riberio et al,. 2020) approach to evaluation of NLP systems has revealed high failure rates for basic capabilities for multiple state-of-the-art and commercial models. However, the CheckList creation process is manual which creates a bottleneck towards creation of multilingual CheckLists catering 100s of languages. In this work, we explore multiple approaches to generate and evaluate the quality of Multilingual CheckList. We device an algorithm &amp;ndash; Automated Multilingual Checklist Generation (AMCG) for automatically transferring a CheckList from a source to a target language that relies on a reasonable machine translation system. We then compare the CheckList generated by AMCG with CheckLists generated with different levels of human intervention. Through in-depth crosslingual experiments between English and Hindi, and broad multilingual experiments spanning 11 languages, we show that the automatic approach can provide accurate estimates of failure rates of a model across capabilities, as would a human-verified CheckList, and better than CheckLists generated by humans from scratch.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vector Space Interpolation for Query Expansion</title>
      <link>https://adityasomak.github.io/publication/interpolation/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/interpolation/</guid>
      <description>&lt;p&gt;Topic-sensitive query set expansion is an important area of research that aims to improve search results for information retrieval. It is particularly crucial for queries related to sensitive and emerging topics. In this work, we describe a method for query set expansion about emerging topics using vector space interpolation. We use a transformer model called OPTIMUS, which is suitable for vector space manipulation due to its variational autoencoder nature. One of our proposed methods – Dirichlet interpolation shows promising results for query expansion. Our methods effectively generate new queries about the sensitive topic by incorporating set-level diversity, which is not captured by traditional sentence-level augmentation methods such as paraphrasing or back-translation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LITMUS Predictor: An AI Assistant for Building Reliable, High-Performing and Fair Multilingual NLP Systems</title>
      <link>https://adityasomak.github.io/publication/litmus/</link>
      <pubDate>Thu, 03 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/litmus/</guid>
      <description>&lt;p&gt;Pre-trained multilingual language models are gaining popularity due to their cross-lingual zero-shot transfer ability, but these models do not perform equally well in all languages. Evaluating task-specific performance of a model in a large number of languages is often a challenge due to lack of labeled data, as is targeting improvements in low performing languages through few-shot learning. We present a tool - LITMUS Predictor - that can make reliable performance projections for a fine-tuned task-specific model in a set of languages without test and training data, and help strategize data labeling efforts to optimize performance and fairness objectives.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing the Effects of Reasoning Types on Cross-Lingual Transfer Performance</title>
      <link>https://adityasomak.github.io/publication/crosslingual/</link>
      <pubDate>Wed, 22 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/crosslingual/</guid>
      <description>&lt;p&gt;Multilingual language models achieve impressive zero-shot accuracies in many languages in complex tasks such as Natural Language Inference (NLI). Examples in NLI (and equivalent complex tasks) often pertain to various types of sub-tasks, requiring different kinds of reasoning. Certain types of reasoning have proven to be more difficult to learn in a monolingual context, and in the crosslingual context, similar observations may shed light on zero-shot transfer efficiency and few-shot sample selection. Hence, to investigate the effects of types of reasoning on transfer performance, we propose a category-annotated multilingual NLI dataset.  We discuss the challenges to scale monolingual annotations to multiple languages. We statistically observe interesting effects that the confluence of reasoning types and language similarities have on transfer performance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing the Nuances of Transformers&#39; Polynomial Simplification Abilities</title>
      <link>https://adityasomak.github.io/publication/polysimp/</link>
      <pubDate>Fri, 07 May 2021 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/polysimp/</guid>
      <description>&lt;p&gt;Symbolic Mathematical tasks such as integration often require multiple welldefined steps and understanding of sub-tasks to reach a solution. To understand Transformers’ abilities in such tasks in a fine-grained manner, we deviate from traditional end-to-end settings, and explore a step-wise polynomial simplification task. Polynomials can be written in a simple normal form as a sum of monomials which are ordered in a lexicographic order. For a polynomial which is not necessarily in this normal form, a sequence of simplification steps is applied to reach the fully simplified (i.e., in the normal form) polynomial. We propose a synthetic Polynomial dataset generation algorithm that generates polynomials with unique proof steps. Through varying coefficient configurations, input representation, proof granularity, and extensive hyper-parameter tuning, we observe that Transformers consistently struggle with numeric multiplication. We explore two ways to mitigate this: Curriculum Learning and a Symbolic Calculator approach (where the numeric operations are offloaded to a calculator). Both approaches provide significant gains over the vanilla Transformers-based baseline.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TaxiNLI: Taking a Ride up the NLU Hill</title>
      <link>https://adityasomak.github.io/publication/taxinli/</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/taxinli/</guid>
      <description>&lt;p&gt;Pre-trained Transformer-based neural architectures have consistently achieved state-of-the-art performance in the Natural Language Inference (NLI) task. Since NLI examples encompass a variety of linguistic, logical, and reasoning phenomena, it remains unclear as to which specific concepts are learnt by the trained systems and where they can achieve strong generalization. To investigate this question, we propose a taxonomic hierarchy of categories that are relevant for the NLI task. We introduce TAXINLI, a new dataset, that has 10k examples from the MNLI dataset (Williams et al., 2018) with these taxonomic labels. Through various experiments on TAXINLI, we observe that whereas for certain taxonomic categories SOTA neural models have achieved near perfect accuracies - a large jump over the previous models - some categories still remain difficult. Our work adds to the growing body of literature that shows the gaps in the current NLI systems and datasets through a systematic presentation and analysis of reasoning categories.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Uncovering Relations for Marketing Knowledge Representation</title>
      <link>https://adityasomak.github.io/publication/makrstarai/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/makrstarai/</guid>
      <description>&lt;p&gt;Online behaviors of consumers and marketers generate massive marketing data, which ever more sophisticated models attempt to turn into insights and aid decisions by
marketers. Yet, in making decisions human managers bring to bear marketing knowledge which reside outside of data and models. Thus, it behooves creation of an automated
marketing knowledge base that can interact with data and models. Currently, marketing knowledge is dispersed in large corpora, but no definitive knowledge base for
marketing exists. Out of the two broad aspects of marketing knowledge - representation and reasoning - this treatise focuses on the former. Specifically,
we focus on creation of marketing knowledge graph from corpora, which requires identification of entities and relations. The relation identification task is
particularly challenging in marketing, because of the non-factoid nature of much marketing knowledge, and the difficulty of forming rules that govern relations.
Specifically, we define a set of relations to capture marketing knowledge, propose a pipeline for creating the knowledge graph from text and propose a
rule-guided semi-supervised relation prediction algorithm to extract relations between marketing entities from sentences.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Integrating Knowledge and Reasoning in Image Understanding</title>
      <link>https://adityasomak.github.io/publication/integratingsurvey/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/integratingsurvey/</guid>
      <description>&lt;p&gt;Deep learning based data-driven approaches have been successfully applied in various image under-
standing applications ranging from object recognition, semantic segmentation to visual question an-
swering.  However, the lack of knowledge integration as well as higher-level reasoning capabilities
with  the  methods  still  pose  a  hindrance. In  this work, we present a brief survey of a few represen-
tative  reasoning  mechanisms,  knowledge  integration methods and their corresponding image under-
standing applications developed by various groups of researchers, approaching the problem from a va-
riety of angles.  Furthermore, we discuss upon key efforts on integrating external knowledge with neu-
ral networks. Taking cues from these efforts, we conclude by discussing potential pathways to im-
prove reasoning capabilities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Knowledge Distillation to aid Visual Reasoning</title>
      <link>https://adityasomak.github.io/publication/spatialkd/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/spatialkd/</guid>
      <description>&lt;p&gt;For tasks involving language and vision, the current state-of-the-art methods do not leverage any additional information
that might be present to gather privileged knowledge. Instead, such an ability is expected to be learnt during the training
phase. One such task is Visual Question Answering, where large diagnostic datasets have been proposed to
test a system’s capability of reasoning and answering questions about images. In
this work, we take a step towards integrating this additional privileged information in the form of spatial knowledge to
aid in visual reasoning. We propose a framework that combines recent advances in knowledge distillation (teacherstudent
framework), relational reasoning and probabilistic logical languages to incorporate such knowledge in existing
neural networks for the surrogate task of fact-based Visual Question Answering. Specifically, for a question posed
against an image, we use a probabilistic logical language to encode the spatial knowledge and the spatial understanding
about the question in the form of a mask that is directly provided to the teacher network. The student network learns
from the ground-truth information as well as the teacher’s prediction via distillation. We also demonstrate the impact
of predicting such a mask inside the teacher’s network using attention. Empirically, we show that both the methods
improve the test accuracy over a state-of-the-art approach on a publicly available dataset.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Explicit Reasoning over End-to-End Neural Architectures</title>
      <link>https://adityasomak.github.io/publication/pslvqa/</link>
      <pubDate>Sat, 17 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/pslvqa/</guid>
      <description>&lt;p&gt;Many vision and language tasks require commonsense reasoning beyond data-driven image and natural language pro-
cessing. Here we adopt Visual Question Answering (VQA) as an example task, where a system is expected to answer a
question in natural language about an image. Current state-of-the-art systems attempted to solve the task using deep neural
architectures and achieved promising performance. However, the resulting systems are generally opaque and they struggle
in understanding questions for which extra knowledge is required. In this paper, we present an explicit reasoning layer on
top of a set of penultimate neural network based systems. The reasoning layer enables reasoning and answering questions
where additional knowledge is required, and at the same time provides an interpretable interface to the end users. Specif-
ically, the reasoning layer adopts a Probabilistic Soft Logic (PSL) based engine to reason over a basket of inputs: visual
relations, semantic parse of the question, and background ontological knowledge from word2vec and ConceptNet.
Experimental analysis of the answers and the key evidential predicates generated on the VQA dataset validate our approach.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards Addressing the Winograd Schema Challenge-Building and Using a Semantic Parser and a Knowledge Hunting Module.</title>
      <link>https://adityasomak.github.io/publication/kparser/</link>
      <pubDate>Sat, 25 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/kparser/</guid>
      <description>&lt;p&gt;Concerned about the Turing test’s ability to correctly
evaluate if a system exhibits human-like intelligence,
the Winograd Schema Challenge (WSC)
has been proposed as an alternative. A Winograd
Schema consists of a sentence and a question. The
answers to the questions are intuitive for humans
but are designed to be difficult for machines, as
they require various forms of commonsense knowledge
about the sentence. In this paper we demonstrate
our progress towards addressing the WSC.
We present an approach that identifies the knowledge
needed to answer a challenge question, hunts
down that knowledge from text repositories, and
then reasons with them to come up with the answer.
In the process we develop a semantic parser
(&lt;a href=&#34;www.kparser.org&#34; target=&#34;_blank&#34;&gt;www.kparser.org&lt;/a&gt;). We show that our approach
works well with respect to a subset of Winograd
schemas.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visual common-sense for scene understanding using perception, semantic parsing and reasoning.</title>
      <link>https://adityasomak.github.io/publication/common-sense/</link>
      <pubDate>Thu, 12 Mar 2015 00:00:00 +0000</pubDate>
      <guid>https://adityasomak.github.io/publication/common-sense/</guid>
      <description>&lt;p&gt;In this paper we explore the use of visual commonsense
knowledge and other kinds of knowledge (such as
domain knowledge, background knowledge, linguistic
knowledge) for scene understanding. In particular, we
combine visual processing with techniques from natural
language understanding (especially semantic parsing),
common-sense reasoning and knowledge representation
and reasoning to improve visual perception to reason
about finer aspects of activities&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
